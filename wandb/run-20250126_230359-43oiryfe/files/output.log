policy_gradient_wx.py:163: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
  state = torch.tensor(state_list, dtype=torch.float).to(device)
/home/lixiang/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
policy_gradient_wx.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  action = torch.tensor(transition_dict['actions']).view(-1, 1).to(self.device)
Episode 0: Loss 8.11215011542663
/home/lixiang/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: [33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
Episode 1: Loss 7.763308870140463
Episode 2: Loss 9.178773857653141
Episode 3: Loss 9.934979625046253
Episode 4: Loss 9.821072904393077
Episode 5: Loss 8.35506503842771
Episode 6: Loss 11.277621762827039
Episode 7: Loss 7.632713599596173
Episode 8: Loss 7.074305278249085
Episode 9: Loss 6.875927255954593
Episode 10: Loss 7.922167552635074
Episode 11: Loss 6.24315471900627
Episode 12: Loss 6.930734714958817
Episode 13: Loss 7.045167370233685
Episode 14: Loss 6.288374730851501
Episode 15: Loss 5.595800346462056
Episode 16: Loss 5.323592438362539
Episode 17: Loss 5.266687875147909
Episode 18: Loss 6.20459661167115
Episode 19: Loss 5.007141581736505
Episode 20: Loss 6.37164754467085
Episode 21: Loss 5.812857212033123
Episode 22: Loss 5.798618524335325
Episode 23: Loss 4.616856783628464
Episode 24: Loss 7.80657474277541
Episode 25: Loss 6.516445786226541
Episode 26: Loss 7.43328051129356
Episode 27: Loss 7.2508647362701595
Episode 28: Loss 7.160404348745942
Episode 29: Loss 11.136225390248
Episode 30: Loss 10.412494755815715
